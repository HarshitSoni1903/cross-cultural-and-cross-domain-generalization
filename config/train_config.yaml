model:
  base_model: "FacebookAI/xlm-roberta-base"
  num_labels: 5
  
training:
  batch_size: 8
  learning_rate: 0.00002  # 2e-5 as float
  num_epochs: 1
  warmup_steps: 500
  weight_decay: 0.01
  max_length: 512
  
data:
  train_languages: ["en"]  # or ["fr"] or ["en", "fr"]
  output_dir: "./outputs"
  save_steps: 1000
  eval_steps: 500
  logging_steps: 100

